{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.23 64-bit ('quantech': conda)",
   "metadata": {
    "interpreter": {
     "hash": "0edbfc4fd16687e9fa556001b096f3c5bef9555faada60aa4e49d2442123d6b7"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.utils import from_scipy_sparse_matrix\n",
    "\n",
    "import optuna\n",
    "import argparse\n",
    "from optuna.samplers import TPESampler\n",
    "import json\n",
    "\n",
    "from models import MODEL_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial experimental settings\n",
    "results_dir = 'GIN-sota'\n",
    "os.makedirs(results_dir, exist_ok=True) #Output directory to save results and model weights\n",
    "batch_size = 512\n",
    "num_epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train_adata = sc.read_h5ad('../../../dataset_10x-visium-processed/dataset_10x-visium_filtered_adatas_hvg-8192/151507.h5ad')\n",
    "X = train_adata.X.toarray() if not isinstance(train_adata.X, np.ndarray) else adata.X\n",
    "Y = LabelEncoder().fit_transform(train_adata.obs['Region'])\n",
    "\n",
    "sc.pp.neighbors(train_adata, n_neighbors=15, use_rep='X')\n",
    "edge_index, _ = from_scipy_sparse_matrix(train_adata.obsp['connectivities'])\n",
    "\n",
    "train_idx, eval_idx = train_test_split(np.arange(len(Y)), test_size=0.2, random_state=42, stratify=Y)\n",
    "\n",
    "data = Data(x=torch.tensor(X, dtype=torch.float),\n",
    "            edge_index=edge_index,\n",
    "            y=torch.tensor(Y, dtype=torch.long))\n",
    "data.train_mask = torch.zeros(len(Y), dtype=torch.bool)\n",
    "data.train_mask[train_idx] = True\n",
    "data.eval_mask = torch.zeros(len(Y), dtype=torch.bool)\n",
    "data.eval_mask[eval_idx] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, loss_fn):\n",
    "    model.eval()\n",
    "    all_preds, all_labels, total_loss = [], [], 0\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = batch.to('cpu')\n",
    "            out = model(batch.x, batch.edge_index)[batch.batch_size:]\n",
    "            loss = loss_fn(out, batch.y[batch.batch_size:])\n",
    "            total_loss += loss.item() * batch.batch_size\n",
    "            all_preds.append(out.argmax(dim=1))\n",
    "            all_labels.append(batch.y[batch.batch_size:])\n",
    "    y_true = torch.cat(all_labels)\n",
    "    y_pred = torch.cat(all_preds)\n",
    "    acc = accuracy_score(y_true.numpy(), y_pred.numpy())\n",
    "    return total_loss / len(loader.dataset), acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'hidden_channels': 128, 'dropout': 0.4605812003658651, 'lr': 0.0024675736770887937, 'num_layers': 2, 'optimizer': 'AdamW'}\n"
     ]
    }
   ],
   "source": [
    "selected_model = 'gin'\n",
    "model_config_path = 'best_model_config.json'\n",
    "# Load the JSON content\n",
    "with open(model_config_path, 'r') as f:\n",
    "    best_params = json.load(f)['params']\n",
    "# Optional: print or inspect the keys\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 01 | Train Acc: 0.4182 | Eval Acc: 0.4088\n",
      "Epoch 02 | Train Acc: 0.6541 | Eval Acc: 0.6529\n",
      "Epoch 03 | Train Acc: 0.6977 | Eval Acc: 0.7130\n",
      "Epoch 04 | Train Acc: 0.7408 | Eval Acc: 0.7420\n",
      "Epoch 05 | Train Acc: 0.8006 | Eval Acc: 0.8064\n",
      "Epoch 06 | Train Acc: 0.8264 | Eval Acc: 0.8166\n",
      "Epoch 07 | Train Acc: 0.8534 | Eval Acc: 0.8580\n",
      "Epoch 08 | Train Acc: 0.8772 | Eval Acc: 0.8718\n",
      "Epoch 09 | Train Acc: 0.9017 | Eval Acc: 0.9037\n",
      "Epoch 10 | Train Acc: 0.9114 | Eval Acc: 0.9083\n",
      "Epoch 11 | Train Acc: 0.9182 | Eval Acc: 0.9025\n",
      "Epoch 12 | Train Acc: 0.9390 | Eval Acc: 0.9350\n",
      "Epoch 13 | Train Acc: 0.9520 | Eval Acc: 0.9450\n",
      "Epoch 14 | Train Acc: 0.9619 | Eval Acc: 0.9621\n",
      "Epoch 15 | Train Acc: 0.9542 | Eval Acc: 0.9505\n",
      "Epoch 16 | Train Acc: 0.9674 | Eval Acc: 0.9678\n",
      "Epoch 17 | Train Acc: 0.9693 | Eval Acc: 0.9565\n",
      "Epoch 18 | Train Acc: 0.9763 | Eval Acc: 0.9779\n",
      "Epoch 19 | Train Acc: 0.9789 | Eval Acc: 0.9750\n",
      "Epoch 20 | Train Acc: 0.9842 | Eval Acc: 0.9783\n",
      "Epoch 21 | Train Acc: 0.9850 | Eval Acc: 0.9776\n",
      "Epoch 22 | Train Acc: 0.9903 | Eval Acc: 0.9831\n",
      "Epoch 23 | Train Acc: 0.9856 | Eval Acc: 0.9816\n",
      "Epoch 24 | Train Acc: 0.9913 | Eval Acc: 0.9886\n",
      "Epoch 25 | Train Acc: 0.9937 | Eval Acc: 0.9912\n",
      "Epoch 26 | Train Acc: 0.9954 | Eval Acc: 0.9939\n",
      "Epoch 27 | Train Acc: 0.9936 | Eval Acc: 0.9927\n",
      "Epoch 28 | Train Acc: 0.9956 | Eval Acc: 0.9931\n",
      "Epoch 29 | Train Acc: 0.9961 | Eval Acc: 0.9973\n",
      "Epoch 30 | Train Acc: 0.9958 | Eval Acc: 0.9953\n",
      "Epoch 31 | Train Acc: 0.9937 | Eval Acc: 0.9933\n",
      "Epoch 32 | Train Acc: 0.9976 | Eval Acc: 0.9946\n",
      "Epoch 33 | Train Acc: 0.9981 | Eval Acc: 0.9973\n",
      "Epoch 34 | Train Acc: 0.9984 | Eval Acc: 0.9939\n",
      "Epoch 35 | Train Acc: 0.9984 | Eval Acc: 0.9959\n",
      "Epoch 36 | Train Acc: 0.9979 | Eval Acc: 0.9938\n",
      "Epoch 37 | Train Acc: 0.9988 | Eval Acc: 0.9966\n",
      "Epoch 38 | Train Acc: 0.9995 | Eval Acc: 0.9952\n",
      "Epoch 39 | Train Acc: 0.9982 | Eval Acc: 0.9979\n",
      "Epoch 40 | Train Acc: 0.9989 | Eval Acc: 0.9993\n",
      "Epoch 41 | Train Acc: 0.9969 | Eval Acc: 0.9945\n",
      "Epoch 42 | Train Acc: 0.9984 | Eval Acc: 0.9959\n",
      "Epoch 43 | Train Acc: 0.9982 | Eval Acc: 0.9966\n",
      "Epoch 44 | Train Acc: 0.9984 | Eval Acc: 0.9946\n",
      "Epoch 45 | Train Acc: 0.9944 | Eval Acc: 0.9960\n",
      "Epoch 46 | Train Acc: 0.9766 | Eval Acc: 0.9780\n",
      "Epoch 47 | Train Acc: 0.9472 | Eval Acc: 0.9404\n",
      "Epoch 48 | Train Acc: 0.9386 | Eval Acc: 0.9489\n",
      "Epoch 49 | Train Acc: 0.9633 | Eval Acc: 0.9593\n",
      "Epoch 50 | Train Acc: 0.9845 | Eval Acc: 0.9813\n",
      "Epoch 51 | Train Acc: 0.9909 | Eval Acc: 0.9928\n",
      "Epoch 52 | Train Acc: 0.9960 | Eval Acc: 0.9940\n",
      "Epoch 53 | Train Acc: 0.9968 | Eval Acc: 0.9966\n",
      "Epoch 54 | Train Acc: 0.9981 | Eval Acc: 0.9960\n",
      "Epoch 55 | Train Acc: 0.9990 | Eval Acc: 0.9973\n",
      "Epoch 56 | Train Acc: 0.9986 | Eval Acc: 0.9966\n",
      "Epoch 57 | Train Acc: 0.9991 | Eval Acc: 0.9960\n",
      "Epoch 58 | Train Acc: 0.9998 | Eval Acc: 0.9993\n",
      "Epoch 59 | Train Acc: 0.9988 | Eval Acc: 0.9979\n",
      "Epoch 60 | Train Acc: 0.9996 | Eval Acc: 0.9993\n",
      "Epoch 61 | Train Acc: 0.9995 | Eval Acc: 0.9993\n",
      "Epoch 62 | Train Acc: 0.9996 | Eval Acc: 1.0000\n",
      "Epoch 63 | Train Acc: 0.9996 | Eval Acc: 0.9993\n",
      "Epoch 64 | Train Acc: 0.9996 | Eval Acc: 0.9993\n",
      "Epoch 65 | Train Acc: 0.9998 | Eval Acc: 0.9986\n",
      "Epoch 66 | Train Acc: 1.0000 | Eval Acc: 0.9993\n",
      "Epoch 67 | Train Acc: 1.0000 | Eval Acc: 1.0000\n",
      "Epoch 68 | Train Acc: 0.9998 | Eval Acc: 0.9993\n",
      "Epoch 69 | Train Acc: 1.0000 | Eval Acc: 1.0000\n",
      "Epoch 70 | Train Acc: 1.0000 | Eval Acc: 1.0000\n",
      "Epoch 71 | Train Acc: 1.0000 | Eval Acc: 1.0000\n",
      "Epoch 72 | Train Acc: 0.9998 | Eval Acc: 1.0000\n",
      "Epoch 73 | Train Acc: 0.9996 | Eval Acc: 0.9993\n",
      "Epoch 74 | Train Acc: 1.0000 | Eval Acc: 1.0000\n",
      "Epoch 75 | Train Acc: 1.0000 | Eval Acc: 0.9993\n",
      "Epoch 76 | Train Acc: 1.0000 | Eval Acc: 1.0000\n",
      "Epoch 77 | Train Acc: 1.0000 | Eval Acc: 1.0000\n",
      "Epoch 78 | Train Acc: 1.0000 | Eval Acc: 1.0000\n",
      "Epoch 79 | Train Acc: 0.9998 | Eval Acc: 1.0000\n",
      "Epoch 80 | Train Acc: 1.0000 | Eval Acc: 0.9986\n",
      "Epoch 81 | Train Acc: 1.0000 | Eval Acc: 1.0000\n",
      "Epoch 82 | Train Acc: 1.0000 | Eval Acc: 0.9993\n",
      "Epoch 83 | Train Acc: 1.0000 | Eval Acc: 1.0000\n",
      "Epoch 84 | Train Acc: 1.0000 | Eval Acc: 1.0000\n",
      "Epoch 85 | Train Acc: 1.0000 | Eval Acc: 1.0000\n",
      "Epoch 86 | Train Acc: 1.0000 | Eval Acc: 1.0000\n",
      "Epoch 87 | Train Acc: 1.0000 | Eval Acc: 1.0000\n",
      "Epoch 88 | Train Acc: 1.0000 | Eval Acc: 0.9993\n",
      "Epoch 89 | Train Acc: 0.9998 | Eval Acc: 1.0000\n",
      "Epoch 90 | Train Acc: 1.0000 | Eval Acc: 1.0000\n",
      "Epoch 91 | Train Acc: 0.9996 | Eval Acc: 1.0000\n",
      "Epoch 92 | Train Acc: 1.0000 | Eval Acc: 0.9987\n",
      "Epoch 93 | Train Acc: 0.9991 | Eval Acc: 0.9967\n",
      "Epoch 94 | Train Acc: 1.0000 | Eval Acc: 1.0000\n",
      "Epoch 95 | Train Acc: 1.0000 | Eval Acc: 1.0000\n",
      "Epoch 96 | Train Acc: 0.9998 | Eval Acc: 0.9993\n",
      "Epoch 97 | Train Acc: 1.0000 | Eval Acc: 1.0000\n",
      "Epoch 98 | Train Acc: 1.0000 | Eval Acc: 1.0000\n",
      "Epoch 99 | Train Acc: 1.0000 | Eval Acc: 1.0000\n",
      "Epoch 100 | Train Acc: 1.0000 | Eval Acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    " # ========== 5. Final Training ==========\n",
    "\n",
    "config_str = f\"{selected_model}_h{best_params['hidden_channels']}_l{best_params['num_layers']}_d{best_params['dropout']:.2f}_lr{best_params['lr']:.0e}\"\n",
    "best_model_path = os.path.join(results_dir, f\"{config_str}.pth\")\n",
    "\n",
    "model = MODEL_CLASSES[selected_model](\n",
    "    in_channels=X.shape[1],\n",
    "    hidden_channels=best_params['hidden_channels'],\n",
    "    out_channels=np.unique(Y).shape[0],\n",
    "    num_layers=best_params['num_layers'],\n",
    "    dropout=best_params['dropout']\n",
    ")\n",
    "optimizer_name = best_params.get('optimizer', 'AdamW')  # Default to AdamW if not present\n",
    "\n",
    "if optimizer_name == 'Adam':\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=best_params['lr'])\n",
    "elif optimizer_name == 'AdamW':\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=best_params['lr'])\n",
    "elif optimizer_name == 'SGD':\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=best_params['lr'], momentum=0.9)\n",
    "elif optimizer_name == 'RMSprop':\n",
    "    optimizer = torch.optim.RMSprop(model.parameters(), lr=best_params['lr'])\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported optimizer: {optimizer_name}\")\n",
    "\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "train_loader = NeighborLoader(data, input_nodes=data.train_mask,\n",
    "                            num_neighbors=[3], batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "eval_loader = NeighborLoader(data, input_nodes=data.eval_mask,\n",
    "                            num_neighbors=[3], batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "train_log = []\n",
    "best_eval_acc = 0\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to('cpu')\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch.x, batch.edge_index)[batch.batch_size:]\n",
    "        loss = loss_fn(out, batch.y[batch.batch_size:])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss, train_acc = evaluate(model, train_loader, loss_fn)\n",
    "    eval_loss, eval_acc = evaluate(model, eval_loader, loss_fn)\n",
    "\n",
    "    if eval_acc > best_eval_acc:\n",
    "        best_eval_acc = eval_acc\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "\n",
    "    train_log.append({\n",
    "        'epoch': epoch,\n",
    "        'train_loss': train_loss,\n",
    "        'train_acc': train_acc,\n",
    "        'eval_loss': eval_loss,\n",
    "        'eval_acc': eval_acc\n",
    "    })\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | Train Acc: {train_acc:.4f} | Eval Acc: {eval_acc:.4f}\")\n",
    "# Save logs\n",
    "with open(os.path.join(results_dir, 'train_log.json'), 'w') as f:\n",
    "    json.dump(train_log, f, indent=2)\n",
    "\n",
    "with open(os.path.join(results_dir, 'best_model_config.json'), 'w') as f:\n",
    "    json.dump({'best_model_path': best_model_path, 'params': best_params}, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Loaded best model from GIN-sota/gin_h128_l2_d0.46_lr2e-03.pth\n",
      "Evaluating:  33%|███▎      | 1/3 [00:02<00:05,  2.95s/it]Test PID 151508 | Accuracy: 0.6076\n",
      "Evaluating:  67%|██████▋   | 2/3 [00:07<00:03,  3.62s/it]Test PID 151509 | Accuracy: 0.6597\n",
      "Evaluating: 100%|██████████| 3/3 [00:10<00:00,  3.56s/it]Test PID 151510 | Accuracy: 0.6528\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ========== 6. Test ==========\n",
    "with open(os.path.join(results_dir, 'best_model_config.json')) as f:\n",
    "    best_model_meta = json.load(f)\n",
    "\n",
    "model = MODEL_CLASSES[selected_model](\n",
    "    in_channels=X.shape[1],\n",
    "    hidden_channels=best_model_meta['params']['hidden_channels'],\n",
    "    out_channels=np.unique(Y).shape[0],\n",
    "    num_layers=best_model_meta['params']['num_layers'],\n",
    "    dropout=best_model_meta['params']['dropout']\n",
    ")\n",
    "model.load_state_dict(torch.load(best_model_meta['best_model_path']))\n",
    "print(f\"\\nLoaded best model from {best_model_meta['best_model_path']}\")\n",
    "\n",
    "test_adata_paths = [\n",
    "    '../../../dataset_10x-visium-processed/dataset_10x-visium_filtered_adatas_hvg-8192/151508.h5ad',\n",
    "    '../../../dataset_10x-visium-processed/dataset_10x-visium_filtered_adatas_hvg-8192/151509.h5ad',\n",
    "    '../../../dataset_10x-visium-processed/dataset_10x-visium_filtered_adatas_hvg-8192/151510.h5ad',\n",
    "]\n",
    "\n",
    "test_results = {}\n",
    "\n",
    "for path in tqdm(test_adata_paths, desc=\"Evaluating\"):\n",
    "    test_pid = path.split('/')[-1].split('.')[0]\n",
    "    adata_test = sc.read_h5ad(path)\n",
    "    X_test = adata_test.X.toarray() if not isinstance(adata_test.X, np.ndarray) else adata_test.X\n",
    "    Y_test = LabelEncoder().fit_transform(adata_test.obs['Region'])\n",
    "\n",
    "    sc.pp.neighbors(adata_test, n_neighbors=3, use_rep='X')\n",
    "    edge_index_test, _ = from_scipy_sparse_matrix(adata_test.obsp['connectivities'])\n",
    "\n",
    "    data_test = Data(x=torch.tensor(X_test, dtype=torch.float),\n",
    "                    edge_index=edge_index_test,\n",
    "                    y=torch.tensor(Y_test, dtype=torch.long))\n",
    "    data_test.test_mask = torch.ones(data_test.num_nodes, dtype=torch.bool)\n",
    "\n",
    "    test_loader = NeighborLoader(\n",
    "        data_test, input_nodes=data_test.test_mask,\n",
    "        num_neighbors=[3], batch_size=16, shuffle=False, num_workers=0)\n",
    "\n",
    "    test_loss, test_acc = evaluate(model, test_loader, loss_fn)\n",
    "    test_results[test_pid] = {'loss': float(test_loss), 'accuracy': float(test_acc)}\n",
    "    print(f\"Test PID {test_pid} | Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "with open(os.path.join(results_dir, 'test_results.json'), 'w') as f:\n",
    "    json.dump(test_results, f, indent=2)\n"
   ]
  }
 ]
}